# ğŸ§  DeepSeek OCR â€“ Multilingual Image-to-Text Extraction

A lightweight and powerful **Optical Character Recognition (OCR)** web app powered by **[DeepSeek-AI/DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR)** and deployed on **Hugging Face Spaces**.  
It supports **Persian**, **English**, and other languages with automatic text recognition from images.

ğŸ”— **Live Demo:** [https://huggingface.co/spaces/samyhusy/OCR](https://huggingface.co/spaces/samyhusy/OCR)

---

## ğŸš€ Features

- ğŸ–¼ï¸ Upload or paste any image containing text  
- ğŸŒ Supports **Persian (Farsi)**, **English**, and **multilingual OCR**  
- âš™ï¸ Built with **Gradio UI** for an intuitive interface  
- âš¡ Optimized for different GPUs (A100, T4, 1660 Ti) using `attn_implementation` variants  
- ğŸ§© Runs locally or in Hugging Face Spaces  
- ğŸ” Transformer-based architecture using **FlashAttention 2** when available  

---

## ğŸ§© Architecture

This app uses the **DeepSeek-OCR** model from the Hugging Face Hub.

```python
from transformers import AutoModel, AutoTokenizer
import torch

model_name = "deepseek-ai/DeepSeek-OCR"
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModel.from_pretrained(
    model_name,
    device_map="auto",
    torch_dtype=torch.float16,
    trust_remote_code=True
)
```

ğŸ–¥ï¸ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/samyvivo/OCR.git
cd OCR
pip install -r requirements.txt
```

If using CUDA:

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124
```

â–¶ï¸ Usage

Run the app locally:
```bash
python main.py
```

hen open the URL shown in your terminal (e.g. http://127.0.0.1:7860) in your browser.

Upload an image, and the model will automatically detect and extract text.

âš™ï¸ GPU Compatibility
```bash
| GPU Type    | Supported `attn_implementation` | Note                           |
| ----------- | ------------------------------- | ------------------------------ |
| A100        | âœ… `"flash_attention_2"`         | Best performance               |
| T4          | âš ï¸ `"eager"` or `"sdpa"`        | FlashAttention 2 not supported |
| GTX 1660 Ti | âš ï¸ `"eager"` only               | Older architecture             |
```

The app automatically detects GPU capability and adjusts configuration.

ğŸ“ Project Structure
```bash
OCR/
â”‚
â”œâ”€â”€ main.py              # Main Gradio application
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ README.md            # Project documentation
â””â”€â”€ assets/              # Example images and logs
```

ğŸ§‘â€ğŸ’» Author

Saman Zeitounian
ğŸ“Š Data Scientist | Machine Learning Engineer

ğŸŒ [LinkedIn](https://www.linkedin.com/in/saman-zeitounian-56a0a5164)

ğŸ’» [GitHub](https://github.com/samyvivo)

ğŸ“ˆ [Kaggle](https://www.kaggle.com/samanzeitounain)

ğŸ“ License

This repository is licensed under the MIT License.
Feel free to use, modify, and share it with attribution.
